{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95f589c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\mihir\\anaconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\mihir\\appdata\\roaming\\python\\python312\\site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\mihir\\appdata\\roaming\\python\\python312\\site-packages (from ucimlrepo) (2025.4.26)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mihir\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mihir\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mihir\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mihir\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mihir\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e2d955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n",
      "(48842, 15)\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55a1d778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      " 14  income          48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f547523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68f8b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income'] = df['income'].str.replace('.', '', regex=False)\n",
    "df['income'] = (df['income'] == '>50K').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b261c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea351315",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0de2b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.values.astype(np.float32)\n",
    "y=y.values.reshape(-1,1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3414ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa6b2e",
   "metadata": {},
   "source": [
    "Activation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "054ecba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "def relu_derivative(z):\n",
    "    return (z>0).astype(float) \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42d28b",
   "metadata": {},
   "source": [
    "BCE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc10628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCE_loss(y,y_hat):\n",
    "    return -np.mean(y*np.log(y_hat+1e-8)+(1-y)*np.log(1-y_hat+1e-8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4130cc",
   "metadata": {},
   "source": [
    "HE initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a107f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_initialisation(in_dim,out_dim):\n",
    "    w=np.random.randn(in_dim,out_dim)* np.sqrt(2.0/in_dim)\n",
    "    b=np.zeros((1,out_dim))\n",
    "    return w,b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f263059",
   "metadata": {},
   "source": [
    "Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a9f0fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_dim,h1,h2):\n",
    "    params={}\n",
    "\n",
    "    params['w1'],params['b1']=he_initialisation(input_dim,h1)\n",
    "    params['w2'],params['b2']=he_initialisation(h1,h2)\n",
    "    params['w3'],params['b3']=he_initialisation(h2,1)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b46b9b",
   "metadata": {},
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34761051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,params):\n",
    "    Z1=X@params['w1']+params['b1']\n",
    "    A1=relu(Z1)\n",
    "\n",
    "    Z2=A1@params['w2']+params['b2']\n",
    "    A2=relu(Z2)\n",
    "\n",
    "    Z3=A2@params['w3']+params['b3']\n",
    "    A3=sigmoid(Z3)\n",
    "\n",
    "    cache={'X':X,'Z1':Z1,'Z2':Z2,'Z3':Z3,'A1':A1,'A2':A2,'A3':A3}\n",
    "\n",
    "    return A3,cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f353a1",
   "metadata": {},
   "source": [
    "Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed757333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bwd(y,params,cache):\n",
    "    m=y.shape[0]\n",
    "    grads={}\n",
    "\n",
    "    #output layer\n",
    "    dZ3=cache['A3']-y\n",
    "    grads['dW3']=cache['A2'].T @ dZ3 /m\n",
    "    grads['db3']=np.mean(dZ3,axis=0,keepdims=True)\n",
    "\n",
    "    # Hidden layer 2\n",
    "    dA2 = dZ3 @ params['w3'].T\n",
    "    dZ2 = dA2 * relu_derivative(cache['Z2'])\n",
    "    grads['dW2'] = cache['A1'].T @ dZ2 / m\n",
    "    grads['db2'] = np.mean(dZ2,axis=0,keepdims=True)\n",
    "\n",
    "    # Hidden layer 1\n",
    "    dA1 = dZ2 @ params['w2'].T\n",
    "    dZ1 = dA1 * relu_derivative(cache['Z1'])\n",
    "    grads['dW1'] = cache['X'].T @ dZ1 / m\n",
    "    grads['db1'] = np.mean(dZ1,axis=0,keepdims=True)\n",
    "\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497c3f1",
   "metadata": {},
   "source": [
    "SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0910a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_optimizer(params,grads,lr):\n",
    "    params['w1']-= lr*grads['dW1']\n",
    "    params['b1']-= lr*grads['db1']\n",
    "\n",
    "    params['w2']-= lr*grads['dW2']\n",
    "    params['b2']-= lr*grads['db2']\n",
    "\n",
    "    params['w3']-= lr*grads['dW3']\n",
    "    params['b3']-= lr*grads['db3']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf24a0",
   "metadata": {},
   "source": [
    "Accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8bbeed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y,y_hat):\n",
    "    preds=(y_hat>0.5).astype(int)\n",
    "    return np.mean(preds==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc1837",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e94814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, y_train, x_test, y_test,\n",
    "          hidden1=64, hidden2=32,\n",
    "          lr=0.01, epochs=2000):\n",
    "\n",
    "    params = model(x_train.shape[1], hidden1, hidden2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        y_hat, cache = forward(x_train, params)\n",
    "        loss = BCE_loss(y_train, y_hat)\n",
    "\n",
    "        grads = bwd(y_train, params, cache)\n",
    "        sgd_optimizer(params, grads, lr)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            train_acc = accuracy(y_train, y_hat)\n",
    "            print(f\"Epoch {epoch} | Loss: {loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # Test evaluation\n",
    "    y_test_hat, _ = forward(x_test, params)\n",
    "    test_acc = accuracy(y_test, y_test_hat)\n",
    "\n",
    "    print(\"\\nFinal Test Accuracy:\", test_acc)\n",
    "    return params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3738796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihir\\AppData\\Local\\Temp\\ipykernel_30332\\259774021.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 14.0339 | Acc: 0.2381\n",
      "Epoch 100 | Loss: 0.6386 | Acc: 0.7612\n",
      "Epoch 200 | Loss: 0.6061 | Acc: 0.7612\n",
      "Epoch 300 | Loss: 0.5860 | Acc: 0.7612\n",
      "Epoch 400 | Loss: 0.5734 | Acc: 0.7612\n",
      "Epoch 500 | Loss: 0.5653 | Acc: 0.7612\n",
      "Epoch 600 | Loss: 0.5601 | Acc: 0.7612\n",
      "Epoch 700 | Loss: 0.5567 | Acc: 0.7612\n",
      "Epoch 800 | Loss: 0.5544 | Acc: 0.7612\n",
      "Epoch 900 | Loss: 0.5529 | Acc: 0.7612\n",
      "Epoch 1000 | Loss: 0.5519 | Acc: 0.7612\n",
      "Epoch 1100 | Loss: 0.5512 | Acc: 0.7612\n",
      "Epoch 1200 | Loss: 0.5507 | Acc: 0.7612\n",
      "Epoch 1300 | Loss: 0.5504 | Acc: 0.7612\n",
      "Epoch 1400 | Loss: 0.5502 | Acc: 0.7612\n",
      "Epoch 1500 | Loss: 0.5501 | Acc: 0.7612\n",
      "Epoch 1600 | Loss: 0.5500 | Acc: 0.7612\n",
      "Epoch 1700 | Loss: 0.5499 | Acc: 0.7612\n",
      "Epoch 1800 | Loss: 0.5498 | Acc: 0.7612\n",
      "Epoch 1900 | Loss: 0.5498 | Acc: 0.7612\n",
      "\n",
      "Final Test Accuracy: 0.7589313133381104\n"
     ]
    }
   ],
   "source": [
    "params=train(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5294de",
   "metadata": {},
   "source": [
    "difference between the two results and conclusion:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffb6f0",
   "metadata": {},
   "source": [
    "when the same fully connected neural network was trained on raw features and on Min–Max scaled features using identical hyperparameters, the final test accuracy remained almost the same in both cases (approximately 75.9%). However, the training dynamics differed substantially. With raw, unscaled data, the initial loss was very high (around 14), the model required roughly 300 epochs to reach 75% accuracy, and training was unstable in the early stages, often accompanied by numerical issues such as sigmoid overflow. In contrast, after applying min–max scaling, the initial loss dropped sharply to about 0.69, the model reached 75% accuracy much faster (within roughly 80–100 epochs), and training remained stable throughout, with little to no numerical warnings. This comparison shows that while feature scaling may not significantly change the final accuracy, it greatly improves convergence speed, numerical stability, and overall training behavior.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
